{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Celeb_directory.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1LkSG8AEyuiaGw0751-8adpzi0hEdZrzP",
      "authorship_tag": "ABX9TyOPIbJm5hjV1vTRND1t4VWg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "viGcWBvA7182",
        "colab_type": "code",
        "outputId": "a91923bd-4ef6-4ec0-8c59-a24c48424f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "!pip install bs4\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4) (4.6.3)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Fetched 252 kB in 2s (154 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (80.0.3987.163-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 91 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ2KvMF9Aimt",
        "colab_type": "text"
      },
      "source": [
        "# **Importing library dependencies**\n",
        "\n",
        "At First the dependencies are imported  - Beautiful Soup  library for parsing the HTML page and selenium and chromium driver for loading the webpage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE68X0Iw_N5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup as soup\n",
        "import codecs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F10r4ly7Ipr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9qQFxBK55UX",
        "colab_type": "text"
      },
      "source": [
        "# **Loading pages and parsing HTML**\n",
        "\n",
        "First the base url page is loaded and then the parsed HTML page is stored. This HTML page is used to extract the celebrity details like celebrity name, image link etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaNuA7TG2DkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_URL = \"http://m.imdb.com/feature/bornondate\" # As given in the problem statement\n",
        "    \n",
        "\t# The page content is dynamic, so, a webdriver is required to emulate a browser\n",
        "\t# environment and run the javascript functions.\n",
        "\n",
        "driver = webdriver.Chrome('chromedriver',options=options)\n",
        "driver.get(BASE_URL)\n",
        "\n",
        "page_html = driver.page_source\n",
        "page_soup=soup(page_html,\"html5lib\")\n",
        "boccat = page_soup.findAll(\"div\", {\"class\":\"lister-item mode-detail\"})\n",
        "driver.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDpz_MA16phT",
        "colab_type": "text"
      },
      "source": [
        "# **Extracting the details individually and storing the details**\n",
        "\n",
        "The HTML file is parsed and then the individual fields are extracted from the parsed HTML document using the HTML tags. In cases if either image, profession or any field is not available then they would display \"Not Available\" or \"No Image Present.\"\n",
        "\n",
        "This data is then written to a file so that it can be viewed efficiently.\n",
        "\n",
        "After each iteration of the inner loop the next page is loaded by accessing the attribute tag avaiable for the next page and the loop terminates only if the attribute tag for the next page is unavailable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDVQ_-fArgXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(\"Sl No    Celebrity Name   Image Link    Profession    Best Work   Early Life\")\n",
        "counter = 1\n",
        "\n",
        "outputFile = codecs.open(\"/content/drive/My Drive/Celebrity_Details.txt\", 'w', \"utf-8\")\n",
        "while(1):\n",
        "  for i in range(len(boccat)):\n",
        "\n",
        "    celebrity_name = boccat[i].find(\"h3\",{\"class\": \"lister-item-header\"}).a.text.strip()\n",
        "    a = boccat[i].findAll(\"p\",{\"class\":\"text-muted text-small\"})\n",
        "    if(len(a)>0):\n",
        "      a=a[0].text.strip().split(\"|\")\n",
        "      \n",
        "      if(len(a)==2):\n",
        "        profession = boccat[i].find(\"p\",{\"class\":\"text-muted text-small\"}).text.strip().split(\"|\")[0]\n",
        "        best_work= boccat[i].find(\"p\",{\"class\":\"text-muted text-small\"}).text.strip().split(\"|\")[1]\n",
        "      else:\n",
        "        best_work=boccat[i].find(\"p\",{\"class\":\"text-muted text-small\"}).text.strip().split(\"|\")[0]\n",
        "        profession=\"Not Avialable\"\n",
        "    else:\n",
        "      profession=\"Not Avialable\"\n",
        "      best_work=\"Not Avialable\"\n",
        "    best_work = best_work.strip()\n",
        "    k=str(i+1)\n",
        "    image_link=boccat[i].findAll(\"img\",{\"alt\":celebrity_name})\n",
        "    if(len(image_link)>0):\n",
        "      image=image_link[0]\n",
        "      image_1= image[\"src\"]\n",
        "    else:\n",
        "      image_1=\"No Image present\"\n",
        "    early_life=boccat[i].findAll(\"p\")\n",
        "    if(len(early_life)>1):\n",
        "\n",
        "      early_life=early_life[1].text.strip()\n",
        "    elif(len(early_life)>0 and len(profession)==0 and len(best_work)==0):\n",
        "      early_life=early_life[0].text.strip()\n",
        "    else:\n",
        "      early_life=\"Not Avialable\"\n",
        "#    print(str(counter)+\"   \"+celebrity_name+ \"    \" +image_1+\"   \"+profession+\"    \"+best_work+\"   \"+early_life)\n",
        "\n",
        "    outputFile.write(\"Serial Number : \" + str(counter) + \"\\n\")\n",
        "    outputFile.write(\"Name of the celebrity: \" + celebrity_name + \"\\n\")\n",
        "    outputFile.write(\"Celebrity Image: \" + image_1.strip() + \"\\n\")\n",
        "    outputFile.write(\"Profession: \" + profession + \"\\n\")\n",
        "    outputFile.write(\"Best Work : \" + best_work + \"\\n\")\n",
        "    outputFile.write(\"Early Life :\" + early_life + \"\\n\")\n",
        "  \n",
        "    outputFile.write(\"\\n\\n\")\n",
        "    \n",
        "    counter=counter+1\n",
        "\n",
        "  next_page=page_soup.findAll(\"a\",{\"class\":\"lister-page-next next-page\"})\n",
        "  if(len(next_page)>0):\n",
        "    next_page=next_page[0]\n",
        "    next_URL=next_page[\"href\"]\n",
        "    driver = webdriver.Chrome('chromedriver',options=options)\n",
        "    driver.get(\"https://www.imdb.com\"+next_URL)\n",
        "\n",
        "\n",
        "    page_html = driver.page_source\n",
        "    driver.close()\n",
        "    page_soup=soup(page_html,\"html5lib\")\n",
        "    boccat = page_soup.findAll(\"div\", {\"class\":\"lister-item mode-detail\"})\n",
        "  else:\n",
        "    break\n",
        "outputFile.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}